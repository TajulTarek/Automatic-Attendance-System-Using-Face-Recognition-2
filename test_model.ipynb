{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tarek\\OneDrive\\Desktop\\Attendance\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\tarek\\OneDrive\\Desktop\\Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet: https://arxiv.org/abs/1512.03385\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "points_detector = dlib.shape_predictor('C:/Users/tarek/OneDrive/Desktop/Attendance/Weights/shape_predictor_68_face_landmarks.dat')\n",
    "face_descriptor_extractor = dlib.face_recognition_model_v1('C:/Users/tarek/OneDrive/Desktop/Attendance/Weights/dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded face descriptors with shape: (45, 128)\n"
     ]
    }
   ],
   "source": [
    "# Load the face_descriptors array\n",
    "descriptors_path='C:/Users/tarek/OneDrive/Desktop/Attendance/Model/face_descriptors_final.npy'\n",
    "loaded_descriptors = np.load(descriptors_path)\n",
    "print(f\"Loaded face descriptors with shape: {loaded_descriptors.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded from C:/Users/tarek/OneDrive/Desktop/Attendance/Model/mp_final.pkl\n",
      "{'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331001/Abhishek3.png': '2020331001', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331001/Abhishek4.png': '2020331001', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331001/WhatsApp Image 2025-01-29 at 12.48.07 PM.jpeg': '2020331001', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331001/WhatsApp Image 2025-01-29 at 12.48.25 PM.jpeg': '2020331001', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331001/WhatsApp Image 2025-01-29 at 12.48.44 PM.jpeg': '2020331001', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331001/WhatsApp Image 2025-01-29 at 12.48.51 PM.jpeg': '2020331001', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331001/WhatsApp Image 2025-01-29 at 12.49.00 PM.jpeg': '2020331001', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331017/Asif1.png': '2020331017', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331017/Asif2.png': '2020331017', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331017/Asif4.png': '2020331017', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/10.jpg': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/2.jpg': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/3.jpg': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/4.jpg': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/5.jpg': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/6.jpg': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/9.jpg': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/Sanjoy1.png': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/Sanjoy2.png': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/Sanjoy3.png': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/Sanjoy5.png': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331023/Sanjoy6.png': '2020331023', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/20250115_151200.jpg': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/20250121_021134.jpg': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/20250121_145559.jpg': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/20250121_145607.jpg': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/20250127_215013.jpg': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/20250127_215015.jpg': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/Nayem1.png': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/Nayem10.png': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/Nayem2.png': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/Nayem3.png': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/Nayem5.png': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/Nayem7.png': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331048/Nayem9.png': '2020331048', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331067/tarek.jpg': '2020331067', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331067/Tarek2.png': '2020331067', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331067/Tarek3.png': '2020331067', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331067/Tarek4.png': '2020331067', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331067/Tarek6.png': '2020331067', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331067/Tarek7.png': '2020331067', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331067/Tarek8.png': '2020331067', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331097/Billah1.png': '2020331097', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331097/Billah2.png': '2020331097', 'C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train/2020331097/Billah4.png': '2020331097'}\n"
     ]
    }
   ],
   "source": [
    "# Load the mp dictionary from a file\n",
    "import pickle\n",
    "def load_mp(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_mp = pickle.load(f)\n",
    "    print(f\"Dictionary loaded from {file_path}\")\n",
    "    return loaded_mp\n",
    "\n",
    "# Load the dictionary\n",
    "loaded_mp = load_mp('C:/Users/tarek/OneDrive/Desktop/Attendance/Model/mp_final.pkl')\n",
    "print(loaded_mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_list = list(loaded_mp.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_name(path):\n",
    "    image=Image.open(path).convert('RGB')\n",
    "    image_np=np.array(image,'uint8')\n",
    "    face_detection=face_detector(image_np,1)\n",
    "    for face in face_detection:\n",
    "        points=points_detector(image_np,face)\n",
    "\n",
    "        face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "        face_descriptor = [f for f in face_descriptor]\n",
    "        face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "        face_descriptor = face_descriptor[np.newaxis, :]\n",
    "\n",
    "        distances = np.linalg.norm(face_descriptor - loaded_descriptors, axis = 1)\n",
    "        min_index=np.argmin(distances)\n",
    "        min_distance=distances[min_index]\n",
    "        print(min_distance)\n",
    "        if min_distance<=0.5:\n",
    "            name_pred=mp_list[min_index][1]\n",
    "        else:\n",
    "            name_pred='Undefined'\n",
    "\n",
    "        #cv2.putText(image_np, 'Pred: ' + str(name_pred), (10, 10), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255))\n",
    "        #cv2.putText(image_np, 'Exp : ' + str(name_real), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "        print(name_pred)\n",
    "\n",
    "    image_np_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image with annotations\n",
    "    #plt.figure(figsize=(6, 6))\n",
    "    #plt.imshow(image_np_rgb)\n",
    "    #plt.axis('off')  # Hide axes\n",
    "    #plt.title(f\"Prediction: {name_pred} | Expected: {name_real}\")\n",
    "    #plt.show()\n",
    "    return name_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(loaded_descriptors[31] - loaded_descriptors[31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\tarek\\\\OneDrive\\\\Desktop\\\\Attendance\\\\cropped\\\\2020331023\\\\3.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test_image_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/tarek/OneDrive/Desktop/Attendance/cropped/2020331023/3.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m predict_name(test_image_path)\n",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m, in \u001b[0;36mpredict_name\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_name\u001b[39m(path):\n\u001b[1;32m----> 2\u001b[0m     image\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     image_np\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(image,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     face_detection\u001b[38;5;241m=\u001b[39mface_detector(image_np,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\tarek\\\\OneDrive\\\\Desktop\\\\Attendance\\\\cropped\\\\2020331023\\\\3.jpg'"
     ]
    }
   ],
   "source": [
    "\n",
    "test_image_path='C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/2020331023/3.jpg'\n",
    "predict_name(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "test_path='C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20190363886369805\n",
      "2020331001\n",
      "True Label: 2020331001, Predicted Label: 2020331001\n",
      "0.27370631794152117\n",
      "2020331001\n",
      "True Label: 2020331001, Predicted Label: 2020331001\n",
      "0.285887820737966\n",
      "2020331017\n",
      "True Label: 2020331017, Predicted Label: 2020331017\n",
      "0.2783898143962235\n",
      "2020331023\n",
      "True Label: 2020331023, Predicted Label: 2020331023\n",
      "0.2881904857723801\n",
      "2020331023\n",
      "True Label: 2020331023, Predicted Label: 2020331023\n",
      "0.22720809994219537\n",
      "2020331023\n",
      "True Label: 2020331023, Predicted Label: 2020331023\n",
      "0.18967203977171337\n",
      "2020331048\n",
      "True Label: 2020331048, Predicted Label: 2020331048\n",
      "0.28761681607553435\n",
      "2020331048\n",
      "True Label: 2020331048, Predicted Label: 2020331048\n",
      "0.22966963733154827\n",
      "2020331048\n",
      "True Label: 2020331048, Predicted Label: 2020331048\n",
      "0.30683223501162343\n",
      "2020331067\n",
      "True Label: 2020331067, Predicted Label: 2020331067\n",
      "0.36590104607438795\n",
      "2020331067\n",
      "True Label: 2020331067, Predicted Label: 2020331067\n",
      "0.2792676108839262\n",
      "2020331097\n",
      "True Label: 2020331097, Predicted Label: 2020331097\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "for class_idx, class_name in enumerate(os.listdir(test_path)):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            true_labels.append(class_name)\n",
    "            predicted_label = predict_name(img_path)\n",
    "            predicted_labels.append(predicted_label)\n",
    "            print(f\"True Label: {class_name}, Predicted Label: {predicted_label}\")\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
