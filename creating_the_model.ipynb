{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet: https://arxiv.org/abs/1512.03385\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "points_detector = dlib.shape_predictor('C:/Users/tarek/OneDrive/Desktop/Attendance/Weights/shape_predictor_68_face_landmarks.dat')\n",
    "face_descriptor_extractor = dlib.face_recognition_model_v1('C:/Users/tarek/OneDrive/Desktop/Attendance/Weights/dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp={}\n",
    "face_descriptors=None\n",
    "folder_path='C:/Users/tarek/OneDrive/Desktop/Attendance/cropped/train'\n",
    "\n",
    "for person in os.listdir(folder_path):\n",
    "    person_path=folder_path+'/'+person\n",
    "    for path in os.listdir(person_path):\n",
    "        img_path=person_path+'/'+path\n",
    "        mp[img_path]=person\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020331001\n",
      "2020331001\n",
      "2020331001\n",
      "2020331001\n",
      "2020331001\n",
      "2020331001\n",
      "2020331001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m image\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m image_np\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(image,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m face_detection\u001b[38;5;241m=\u001b[39mface_detector(image_np,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(person)\n\u001b[0;32m      9\u001b[0m c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for img_path, person in mp.items():\n",
    "    # Check if the path is a file before opening it\n",
    "    if os.path.isfile(img_path):\n",
    "        image=Image.open(img_path).convert(\"RGB\")\n",
    "        image_np=np.array(image,'uint8')\n",
    "\n",
    "        face_detection=face_detector(image_np,1)\n",
    "        print(person)\n",
    "        c=0\n",
    "        for face in face_detection:\n",
    "            points=points_detector(image_np,face)\n",
    "\n",
    "            face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "            face_descriptor = [f for f in face_descriptor]\n",
    "            face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "            face_descriptor = face_descriptor[np.newaxis, :]\n",
    "\n",
    "\n",
    "            if face_descriptors is None:\n",
    "                face_descriptors=face_descriptor\n",
    "            else:\n",
    "                face_descriptors= np.concatenate((face_descriptors, face_descriptor), axis = 0)\n",
    "    else:\n",
    "        # If it's a directory, print a message or handle it appropriately\n",
    "        print(f\"Skipping directory: {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(face_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face descriptors saved to C:/Users/tarek/OneDrive/Desktop/Attendance/Model/face_descriptors.npy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to save the descriptors\n",
    "save_path = 'C:/Users/tarek/OneDrive/Desktop/Attendance/Model/face_descriptors.npy'\n",
    "\n",
    "# Save the face_descriptors array\n",
    "np.save(save_path, face_descriptors)\n",
    "print(f\"Face descriptors saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded face descriptors with shape: (70, 128)\n"
     ]
    }
   ],
   "source": [
    "# Load the face_descriptors array\n",
    "loaded_descriptors = np.load(save_path)\n",
    "print(f\"Loaded face descriptors with shape: {loaded_descriptors.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to C:/Users/tarek/OneDrive/Desktop/Attendance/Model/mp.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the mp dictionary to a file\n",
    "def save_mp(mp, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(mp, f)\n",
    "    print(f\"Dictionary saved to {file_path}\")\n",
    "\n",
    "# Specify the file path\n",
    "mp_file_path = 'C:/Users/tarek/OneDrive/Desktop/Attendance/Model/mp.pkl'\n",
    "save_mp(mp, mp_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded from C:/Users/tarek/OneDrive/Desktop/Attendance/Model/mp.pkl\n",
      "{'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Abdullah_Gul/Abdullah_Gul_0001.jpg': 'Abdullah_Gul', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Abdullah_Gul/Abdullah_Gul_0003.jpg': 'Abdullah_Gul', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Abdullah_Gul/Abdullah_Gul_0004.jpg': 'Abdullah_Gul', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Abdullah_Gul/Abdullah_Gul_0005.jpg': 'Abdullah_Gul', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Abdullah_Gul/Abdullah_Gul_0006.jpg': 'Abdullah_Gul', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Abdullah_Gul/Abdullah_Gul_0007.jpg': 'Abdullah_Gul', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Abdullah_Gul/Abdullah_Gul_0008.jpg': 'Abdullah_Gul', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Abdullah_Gul/Abdullah_Gul_0010.jpg': 'Abdullah_Gul', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Adrien_Brody/Adrien_Brody_0001.jpg': 'Adrien_Brody', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Adrien_Brody/Adrien_Brody_0003.jpg': 'Adrien_Brody', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Adrien_Brody/Adrien_Brody_0004.jpg': 'Adrien_Brody', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Adrien_Brody/Adrien_Brody_0005.jpg': 'Adrien_Brody', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Adrien_Brody/Adrien_Brody_0006.jpg': 'Adrien_Brody', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Adrien_Brody/Adrien_Brody_0007.jpg': 'Adrien_Brody', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Adrien_Brody/Adrien_Brody_0008.jpg': 'Adrien_Brody', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Adrien_Brody/Adrien_Brody_0010.jpg': 'Adrien_Brody', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alejandro_Toledo/Alejandro_Toledo_0001.jpg': 'Alejandro_Toledo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alejandro_Toledo/Alejandro_Toledo_0003.jpg': 'Alejandro_Toledo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alejandro_Toledo/Alejandro_Toledo_0004.jpg': 'Alejandro_Toledo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alejandro_Toledo/Alejandro_Toledo_0005.jpg': 'Alejandro_Toledo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alejandro_Toledo/Alejandro_Toledo_0006.jpg': 'Alejandro_Toledo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alejandro_Toledo/Alejandro_Toledo_0007.jpg': 'Alejandro_Toledo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alejandro_Toledo/Alejandro_Toledo_0008.jpg': 'Alejandro_Toledo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alejandro_Toledo/Alejandro_Toledo_0010.jpg': 'Alejandro_Toledo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alvaro_Uribe/Alvaro_Uribe_0001.jpg': 'Alvaro_Uribe', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alvaro_Uribe/Alvaro_Uribe_0003.jpg': 'Alvaro_Uribe', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alvaro_Uribe/Alvaro_Uribe_0004.jpg': 'Alvaro_Uribe', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alvaro_Uribe/Alvaro_Uribe_0005.jpg': 'Alvaro_Uribe', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alvaro_Uribe/Alvaro_Uribe_0006.jpg': 'Alvaro_Uribe', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alvaro_Uribe/Alvaro_Uribe_0007.jpg': 'Alvaro_Uribe', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alvaro_Uribe/Alvaro_Uribe_0008.jpg': 'Alvaro_Uribe', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Alvaro_Uribe/Alvaro_Uribe_0010.jpg': 'Alvaro_Uribe', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Amelie_Mauresmo/Amelie_Mauresmo_0001.jpg': 'Amelie_Mauresmo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Amelie_Mauresmo/Amelie_Mauresmo_0003.jpg': 'Amelie_Mauresmo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Amelie_Mauresmo/Amelie_Mauresmo_0004.jpg': 'Amelie_Mauresmo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Amelie_Mauresmo/Amelie_Mauresmo_0005.jpg': 'Amelie_Mauresmo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Amelie_Mauresmo/Amelie_Mauresmo_0006.jpg': 'Amelie_Mauresmo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Amelie_Mauresmo/Amelie_Mauresmo_0007.jpg': 'Amelie_Mauresmo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Amelie_Mauresmo/Amelie_Mauresmo_0008.jpg': 'Amelie_Mauresmo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Amelie_Mauresmo/Amelie_Mauresmo_0010.jpg': 'Amelie_Mauresmo', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andre_Agassi/Andre_Agassi_0001.jpg': 'Andre_Agassi', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andre_Agassi/Andre_Agassi_0003.jpg': 'Andre_Agassi', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andre_Agassi/Andre_Agassi_0004.jpg': 'Andre_Agassi', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andre_Agassi/Andre_Agassi_0005.jpg': 'Andre_Agassi', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andre_Agassi/Andre_Agassi_0006.jpg': 'Andre_Agassi', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andre_Agassi/Andre_Agassi_0007.jpg': 'Andre_Agassi', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andre_Agassi/Andre_Agassi_0010.jpg': 'Andre_Agassi', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andy_Roddick/Andy_Roddick_0006.jpg': 'Andy_Roddick', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andy_Roddick/Andy_Roddick_0007.jpg': 'Andy_Roddick', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Andy_Roddick/Andy_Roddick_0008.jpg': 'Andy_Roddick', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Angelina_Jolie/Angelina_Jolie_0001.jpg': 'Angelina_Jolie', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Angelina_Jolie/Angelina_Jolie_0003.jpg': 'Angelina_Jolie', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Angelina_Jolie/Angelina_Jolie_0004.jpg': 'Angelina_Jolie', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Angelina_Jolie/Angelina_Jolie_0005.jpg': 'Angelina_Jolie', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Angelina_Jolie/Angelina_Jolie_0006.jpg': 'Angelina_Jolie', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Angelina_Jolie/Angelina_Jolie_0007.jpg': 'Angelina_Jolie', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Angelina_Jolie/Angelina_Jolie_0008.jpg': 'Angelina_Jolie', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Angelina_Jolie/Angelina_Jolie_0010.jpg': 'Angelina_Jolie', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Anna_Kournikova/Anna_Kournikova_0001.jpg': 'Anna_Kournikova', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Anna_Kournikova/Anna_Kournikova_0003.jpg': 'Anna_Kournikova', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Anna_Kournikova/Anna_Kournikova_0004.jpg': 'Anna_Kournikova', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Anna_Kournikova/Anna_Kournikova_0006.jpg': 'Anna_Kournikova', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Anna_Kournikova/Anna_Kournikova_0007.jpg': 'Anna_Kournikova', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Anna_Kournikova/Anna_Kournikova_0008.jpg': 'Anna_Kournikova', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Anna_Kournikova/Anna_Kournikova_0010.jpg': 'Anna_Kournikova', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Ann_Veneman/Ann_Veneman_0001.jpg': 'Ann_Veneman', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Ann_Veneman/Ann_Veneman_0003.jpg': 'Ann_Veneman', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Ann_Veneman/Ann_Veneman_0004.jpg': 'Ann_Veneman', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Ann_Veneman/Ann_Veneman_0005.jpg': 'Ann_Veneman', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Ann_Veneman/Ann_Veneman_0006.jpg': 'Ann_Veneman', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Ann_Veneman/Ann_Veneman_0007.jpg': 'Ann_Veneman', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Ann_Veneman/Ann_Veneman_0008.jpg': 'Ann_Veneman', 'C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/train_data/Ann_Veneman/Ann_Veneman_0010.jpg': 'Ann_Veneman'}\n"
     ]
    }
   ],
   "source": [
    "# Load the mp dictionary from a file\n",
    "def load_mp(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_mp = pickle.load(f)\n",
    "    print(f\"Dictionary loaded from {file_path}\")\n",
    "    return loaded_mp\n",
    "\n",
    "# Load the dictionary\n",
    "loaded_mp = load_mp(mp_file_path)\n",
    "print(loaded_mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(face_descriptors[31] - face_descriptors[31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_list = list(mp.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_name(path):\n",
    "    image=Image.open(path).convert('RGB')\n",
    "    image_np=np.array(image,'uint8')\n",
    "    face_detection=face_detector(image_np,1)\n",
    "    for face in face_detection:\n",
    "        points=points_detector(image_np,face)\n",
    "\n",
    "        face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "        face_descriptor = [f for f in face_descriptor]\n",
    "        face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "        face_descriptor = face_descriptor[np.newaxis, :]\n",
    "\n",
    "        distances = np.linalg.norm(face_descriptor - face_descriptors, axis = 1)\n",
    "        min_index=np.argmin(distances)\n",
    "        min_distance=distances[min_index]\n",
    "        print(min_distance)\n",
    "        if min_distance<=0.5:\n",
    "            name_pred=mp_list[min_index][1]\n",
    "        else:\n",
    "            name_pred='Undefined'\n",
    "\n",
    "        #cv2.putText(image_np, 'Pred: ' + str(name_pred), (10, 10), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255))\n",
    "        #cv2.putText(image_np, 'Exp : ' + str(name_real), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "        print(name_pred)\n",
    "\n",
    "    image_np_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image with annotations\n",
    "    #plt.figure(figsize=(6, 6))\n",
    "    #plt.imshow(image_np_rgb)\n",
    "    #plt.axis('off')  # Hide axes\n",
    "    #plt.title(f\"Prediction: {name_pred} | Expected: {name_real}\")\n",
    "    #plt.show()\n",
    "    return name_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37042756861991755\n",
      "Adrien_Brody\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Adrien_Brody'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_image_path='C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/test_data/Adrien_Brody/Adrien_Brody_0002.jpg'\n",
    "predict_name(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "test_path='C:/Users/tarek/OneDrive/Desktop/Attendance/Dataset10/test_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26260905854086763\n",
      "Abdullah_Gul\n",
      "True Label: Abdullah_Gul, Predicted Label: Abdullah_Gul\n",
      "0.27672721950998846\n",
      "Abdullah_Gul\n",
      "True Label: Abdullah_Gul, Predicted Label: Abdullah_Gul\n",
      "0.37042756861991755\n",
      "Adrien_Brody\n",
      "True Label: Adrien_Brody, Predicted Label: Adrien_Brody\n",
      "0.30508340202491196\n",
      "Adrien_Brody\n",
      "True Label: Adrien_Brody, Predicted Label: Adrien_Brody\n",
      "0.3828451337541834\n",
      "Alejandro_Toledo\n",
      "True Label: Alejandro_Toledo, Predicted Label: Alejandro_Toledo\n",
      "0.31092263070574816\n",
      "Alejandro_Toledo\n",
      "True Label: Alejandro_Toledo, Predicted Label: Alejandro_Toledo\n",
      "0.4756401379969058\n",
      "Alvaro_Uribe\n",
      "True Label: Alvaro_Uribe, Predicted Label: Alvaro_Uribe\n",
      "0.40881713753803917\n",
      "Alvaro_Uribe\n",
      "True Label: Alvaro_Uribe, Predicted Label: Alvaro_Uribe\n",
      "0.4894663331154778\n",
      "Amelie_Mauresmo\n",
      "True Label: Amelie_Mauresmo, Predicted Label: Amelie_Mauresmo\n",
      "0.4178009716359955\n",
      "Amelie_Mauresmo\n",
      "True Label: Amelie_Mauresmo, Predicted Label: Amelie_Mauresmo\n",
      "0.34861814945346586\n",
      "Angelina_Jolie\n",
      "True Label: Angelina_Jolie, Predicted Label: Angelina_Jolie\n",
      "0.34130446849505697\n",
      "Angelina_Jolie\n",
      "True Label: Angelina_Jolie, Predicted Label: Angelina_Jolie\n",
      "0.5529586393711426\n",
      "Undefined\n",
      "True Label: Anna_Kournikova, Predicted Label: Undefined\n",
      "0.33972230734027753\n",
      "Ann_Veneman\n",
      "True Label: Ann_Veneman, Predicted Label: Ann_Veneman\n",
      "0.31877311003918657\n",
      "Anna_Kournikova\n",
      "True Label: Ann_Veneman, Predicted Label: Anna_Kournikova\n",
      "Test Accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "for class_idx, class_name in enumerate(os.listdir(test_path)):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            true_labels.append(class_name)\n",
    "            predicted_label = predict_name(img_path)\n",
    "            predicted_labels.append(predicted_label)\n",
    "            print(f\"True Label: {class_name}, Predicted Label: {predicted_label}\")\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
